{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3407534a-a82e-450d-a751-71ad70e18a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6afac5a3-b7ed-491e-8a31-ab1d58568547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path, target_size):\n",
    "    # Görüntüyü yükleme ve boyutlandırma\n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    # Görüntüyü numpy dizisine dönüştürme\n",
    "    img_array = image.img_to_array(img)\n",
    "    # Boyutu genişletme\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89271b98-bd25-4166-a41b-2b13936a578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path, tokenizer_path):\n",
    "    model = load_model(model_path)\n",
    "    with open(os.path.join(tokenizer_path,\"caption.pkl\"), \"rb\") as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7e8e26a-ad96-47f9-b4a5-081ba2f20c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(model, tokenizer, image_path, max_sequence_length):\n",
    "    start_token = 'startseq'\n",
    "    end_token = 'endseq'\n",
    "    max_length = max_sequence_length - 1\n",
    "    \n",
    "    in_text = start_token\n",
    "    for _ in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([image_path, sequence], verbose=1)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = word_for_id(yhat, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == end_token:\n",
    "            break\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60a518bb-f1e1-49d1-a808-1c64ffc2d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'C:/Users/mert_/Desktop/xd/realProje/indir.jpg'\n",
    "model_path = 'C:/Users/mert_/Desktop/xd/realProje/model.h5'\n",
    "tokenizer_path = 'C:/Users/mert_/Desktop/xd/realProje'\n",
    "\n",
    "target_size = (224,224,3)  \n",
    "max_sequence_length = 35   # Caption'ın maksimum uzunluğu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cff830d7-4feb-4f95-9694-3b9f8cc3126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 7.  6.  2.]\n",
      "   [ 7.  6.  2.]\n",
      "   [ 7.  6.  2.]\n",
      "   ...\n",
      "   [51. 30. 11.]\n",
      "   [50. 32. 12.]\n",
      "   [51. 32. 15.]]\n",
      "\n",
      "  [[ 5.  4.  2.]\n",
      "   [ 5.  4.  2.]\n",
      "   [ 5.  4.  2.]\n",
      "   ...\n",
      "   [56. 34. 13.]\n",
      "   [51. 32. 15.]\n",
      "   [48. 30. 16.]]\n",
      "\n",
      "  [[ 5.  3.  4.]\n",
      "   [ 4.  2.  3.]\n",
      "   [ 6.  4.  5.]\n",
      "   ...\n",
      "   [61. 36. 16.]\n",
      "   [51. 29. 15.]\n",
      "   [40. 26. 15.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   ...\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   ...\n",
      "   [ 1.  1.  1.]\n",
      "   [ 1.  1.  1.]\n",
      "   [ 2.  2.  2.]]\n",
      "\n",
      "  [[ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   [ 2.  2.  2.]\n",
      "   ...\n",
      "   [ 3.  3.  3.]\n",
      "   [ 3.  3.  3.]\n",
      "   [ 2.  2.  2.]]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 4096), found shape=(None, 224, 224, 3)\n",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[59], line 4\u001b[0m\n    caption = generate_caption(model, tokenizer, img, max_sequence_length)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[51], line 10\u001b[0m in \u001b[0;35mgenerate_caption\u001b[0m\n    yhat = model.predict([image_path, sequence], verbose=1)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m in \u001b[0;35merror_handler\u001b[0m\n    raise e.with_traceback(filtered_tb) from None\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo_fn_km7.py:18\u001b[1;36m in \u001b[1;35mtf__predict_function\u001b[1;36m\n\u001b[1;33m    raise\u001b[1;36m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m in user code:\n\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\mert_\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 4096), found shape=(None, 224, 224, 3)\n\n"
     ]
    }
   ],
   "source": [
    "img = load_and_preprocess_image(image_path, target_size)\n",
    "print(img)\n",
    "model, tokenizer = load_model_and_tokenizer(model_path, tokenizer_path)\n",
    "caption = generate_caption(model, tokenizer, img, max_sequence_length)\n",
    "print(\"Generated Caption:\", caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
